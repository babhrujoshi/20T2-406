


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Home page for CPSC406 Term 2 2020">
      
      
        <link rel="canonical" href="https://babhrujoshi.github.io/20T2-406/InclassActivity/mlactivity/">
      
      
        <meta name="author" content="Michael P. Friedlander and Babhru Joshi">
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-5.2.3">
    
    
      
        <title>**CPSC 406: In class activity 1 (Due date: Feb 26, 11:59pm)** - CPSC406 &mdash; Computational Optimization</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6e35a1a6.min.css">
      
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
        
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-4736412-7","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}),document.addEventListener("DOMContentSwitch",function(){ga("send","pageview")})</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
  
    <body dir="ltr">
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#cpsc-406-in-class-activity-1-due-date-feb-26-1159pm" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="https://babhrujoshi.github.io/20T2-406/" title="CPSC406 &mdash; Computational Optimization" class="md-header-nav__button md-logo" aria-label="CPSC406 &mdash; Computational Optimization">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            CPSC406 &mdash; Computational Optimization
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              **CPSC 406: In class activity  1 (Due date: Feb 26, 11:59pm)**
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://babhrujoshi.github.io/20T2-406/" title="CPSC406 &mdash; Computational Optimization" class="md-nav__button md-logo" aria-label="CPSC406 &mdash; Computational Optimization">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    CPSC406 &mdash; Computational Optimization
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Home Page" class="md-nav__link">
      Home Page
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../grades/" title="Grades" class="md-nav__link">
      Grades
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../schedule/" title="Schedule" class="md-nav__link">
      Schedule
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      Lecture notes
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Lecture notes" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Lecture notes
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/background/" title="Mathematical background" class="md-nav__link">
      Mathematical background
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/Least_squares/" title="Least squares" class="md-nav__link">
      Least squares
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/QR_factorization/" title="QR factorization" class="md-nav__link">
      QR factorization
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/Regularized_LS/" title="Regularized least squares" class="md-nav__link">
      Regularized least squares
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/Non-linear_LS/" title="Non-linear least squares" class="md-nav__link">
      Non-linear least squares
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/unconstrained/" title="Unconstrained optimization" class="md-nav__link">
      Unconstrained optimization
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/Gradient_Descent/" title="Gradient descent" class="md-nav__link">
      Gradient descent
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/Newtons_method/" title="Newton's method" class="md-nav__link">
      Newton's method
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/Quasi_newton/" title="Quasi-Newton methods" class="md-nav__link">
      Quasi-Newton methods
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/Linear_constraint/" title="Linear constraint" class="md-nav__link">
      Linear constraint
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/Convex_set/" title="Convex sets" class="md-nav__link">
      Convex sets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/Constrained_optimization/" title="Constrained optimization" class="md-nav__link">
      Constrained optimization
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/Convex_function/" title="Convex function" class="md-nav__link">
      Convex function
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/Linear_programming/" title="Linear programming" class="md-nav__link">
      Linear programming
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Homework
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Homework" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Homework
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../homework/" title="Submissions" class="md-nav__link">
      Submissions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../homework/hw1/hw1/" title="Homework 1" class="md-nav__link">
      Homework 1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../homework/hw2/hw2/" title="Homework 2" class="md-nav__link">
      Homework 2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../homework/hw3/hw3/" title="Homework 3" class="md-nav__link">
      Homework 3
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      In-class Activity
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="In-class Activity" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        In-class Activity
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="mlactivity/" title="Digit classification" class="md-nav__link">
      Digit classification
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  
                
                
                <h1 id="cpsc-406-in-class-activity-1-due-date-feb-26-1159pm"><strong>CPSC 406: In class activity  1 (Due date: Feb 26, 11:59pm)</strong><a class="headerlink" href="#cpsc-406-in-class-activity-1-due-date-feb-26-1159pm" title="Permanent link">&para;</a></h1>
<p>In homework 2, you used <code>Convex.jl</code> to minimize multi-objective problems. Ready-built solvers are great tools for prototyping, because it helps limit bugs to modeling errors. However, often there is a tradeoff, whether in scalability, or in generality. In this homework, you will program your own optimization methods on several machine learning problems.</p>
<ol>
<li>
<p><strong>Retrieving data.</strong> Download <a href="../mnist.mat">mnist.mat</a>. This dataset contains 28 x 28 black and white images of handwritten digits, 0,...,9. Install package <code>MAT</code> to  open and read the dataset.</p>
<div class="highlight"><pre><span></span><code><span class="k">using</span> <span class="n">MAT</span><span class="p">,</span> <span class="n">Plots</span><span class="p">,</span> <span class="n">Images</span><span class="p">,</span> <span class="n">LinearAlgebra</span><span class="p">,</span> <span class="n">ImageView</span><span class="p">,</span> <span class="n">Colors</span><span class="p">,</span> <span class="n">Statistics</span>
<span class="c"># open file</span>
<span class="n">file</span> <span class="o">=</span> <span class="n">matopen</span><span class="p">(</span><span class="s">&quot;mnist.mat&quot;</span><span class="p">)</span>
<span class="n">trainX</span> <span class="o">=</span> <span class="n">float64</span><span class="o">.</span><span class="p">(</span><span class="n">read</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s">&quot;trainX&quot;</span><span class="p">))</span>
<span class="n">trainY</span> <span class="o">=</span> <span class="n">float64</span><span class="o">.</span><span class="p">(</span><span class="n">read</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s">&quot;trainY&quot;</span><span class="p">))</span>
<span class="n">testX</span> <span class="o">=</span> <span class="n">float64</span><span class="o">.</span><span class="p">(</span><span class="n">read</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s">&quot;testX&quot;</span><span class="p">))</span>
<span class="n">testY</span> <span class="o">=</span> <span class="n">float64</span><span class="o">.</span><span class="p">(</span><span class="n">read</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s">&quot;testY&quot;</span><span class="p">));</span>
</code></pre></div>

<p>The actual picture itself has been vectorized. To view image <span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> (where, for the trainig set, <span><span class="MathJax_Preview">i = 1,...,60000</span><script type="math/tex">i = 1,...,60000</script></span>) type the following commands</p>
<div class="highlight"><pre><span></span><code><span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">trainX</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="o">:</span><span class="p">],</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span><span class="o">&#39;</span><span class="p">;</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">heatmap</span><span class="p">(</span><span class="n">Gray</span><span class="o">.</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>
<span class="n">plot</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s">&quot;</span><span class="si">$</span><span class="p">(</span><span class="n">trainY</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="kc">false</span><span class="p">)</span>
</code></pre></div>

<p>You should get one of the 4 images show below.
<center>
    <img src="../figures/sample_digits.png" width = "300"> </p>
<p></center></p>
</li>
<li>
<p><strong>Preprocessing</strong> In this homework you will implement several binary classification models in order to   disambiguate 4 from 9. In order to do so, we need a matrix <span><span class="MathJax_Preview">A\in \R^{m\times n}</span><script type="math/tex">A\in \R^{m\times n}</script></span> where <span><span class="MathJax_Preview">m = \red{?}</span><script type="math/tex">m = \red{?}</script></span> is the number of training samples, and <span><span class="MathJax_Preview">n = 28\times 28 = 784</span><script type="math/tex">n = 28\times 28 = 784</script></span> is the feature length. Additionally, we need a vector <span><span class="MathJax_Preview">b\in \R^m</span><script type="math/tex">b\in \R^m</script></span> where <span><span class="MathJax_Preview">b_i = +1</span><script type="math/tex">b_i = +1</script></span> if the <span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>th sample is a 4, and <span><span class="MathJax_Preview">-1</span><script type="math/tex">-1</script></span> if it is a 9. As in many data science projects, the first step is in processing the data in  order to find these constants.</p>
<ol>
<li>
<p>First, filter out all the datapoints in the test and train set corresponding to any sample that is not a 4 or 9. With the train data, this can be done using</p>
<div class="highlight"><pre><span></span><code><span class="c"># pull out 4s and 9s from train set</span>
<span class="n">idx4</span> <span class="o">=</span> <span class="n">trainY</span> <span class="o">.==</span> <span class="mi">4</span> 
<span class="n">idx9</span> <span class="o">=</span> <span class="n">trainY</span> <span class="o">.==</span> <span class="mi">9</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">idx4</span> <span class="o">+</span> <span class="n">idx9</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">findall</span><span class="p">(</span><span class="n">x</span><span class="o">-&gt;</span><span class="n">x</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">idx</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="o">:</span><span class="p">])</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">trainX</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="o">:</span><span class="p">]</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">trainY</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</code></pre></div>

<p>Do something similar to generate <em>Atest</em> and <em>btest</em>.</p>
</li>
<li>
<p>Now, transform <span><span class="MathJax_Preview">b</span><script type="math/tex">b</script></span> so that instead of taking labels 4 and 9, it takes labels +1 and -1. </p>
</li>
<li>
<p><strong>De-biasing and normalizing</strong> Two tricks that often make models work a lot better is removing the bias and making the variance as close to 0 as possible. To remove the bias, perform </p>
<div class="highlight"><pre><span></span><code><span class="n">Amean</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="mi">1</span><span class="p">);</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">A</span> <span class="o">-</span> <span class="n">ones</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">Amean</span><span class="p">;</span>
</code></pre></div>

<p>To remove the variance, perform</p>
<div class="highlight"><pre><span></span><code><span class="n">Astd</span> <span class="o">=</span> <span class="n">std</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="mi">1</span><span class="p">);</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">A</span> <span class="o">./</span> <span class="p">(</span><span class="n">ones</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">max</span><span class="o">.</span><span class="p">(</span><span class="n">Astd</span><span class="p">,</span><span class="mi">1</span><span class="p">));</span>
</code></pre></div>

<p>The extra normalization of the denominator is to avoid dividing by 0. Note that <em>order matters</em>; we cannot remove the variance before removing the mean. (Why?) Note also we actually divide by the standard deviation of <span><span class="MathJax_Preview">X</span><script type="math/tex">X</script></span>, which is the square root of the variance. </p>
</li>
</ol>
</li>
<li>
<p>We now have our data matrix <span><span class="MathJax_Preview">A</span><script type="math/tex">A</script></span> and label matrix <span><span class="MathJax_Preview">b</span><script type="math/tex">b</script></span> corresponding to the training set. Now, we want </p>
<div>
<div class="MathJax_Preview">x_{LS} = \argmin_x \|Ax-b\|_2^2</div>
<script type="math/tex; mode=display">x_{LS} = \argmin_x \|Ax-b\|_2^2</script>
</div>
<ol>
<li>
<p>Solve this using a direct method (e.g. <span><span class="MathJax_Preview">A \backslash b</span><script type="math/tex">A \backslash b</script></span>). Evaluate the <em>loss</em> of the model</p>
<div>
<div class="MathJax_Preview">\text{loss}(x_{LS}) = \|Ax-b\|_2^2.</div>
<script type="math/tex; mode=display">\text{loss}(x_{LS}) = \|Ax-b\|_2^2.</script>
</div>
</li>
<li>
<p>Discuss how to now construct a <em>classifier</em>, e.g. some function <span><span class="MathJax_Preview">C_x(a)</span><script type="math/tex">C_x(a)</script></span> that takes some feature vector <span><span class="MathJax_Preview">a\in \R^m</span><script type="math/tex">a\in \R^m</script></span> and returns <span><span class="MathJax_Preview">+1</span><script type="math/tex">+1</script></span> if the image is a 4, and <span><span class="MathJax_Preview">-1</span><script type="math/tex">-1</script></span> otherwise. Evaluate the <em>training misclassification rate</em></p>
<div>
<div class="MathJax_Preview">\texttt{train misclass rate}(x_{LS}) = \frac{1}{m}\sum_{i=1}^m I(C_{x_{LS}}(A_i), b_i)</div>
<script type="math/tex; mode=display">\texttt{train misclass rate}(x_{LS}) = \frac{1}{m}\sum_{i=1}^m I(C_{x_{LS}}(A_i), b_i)</script>
</div>
<p>where <span><span class="MathJax_Preview">I(x,y) = 1</span><script type="math/tex">I(x,y) = 1</script></span> if <span><span class="MathJax_Preview">x\neq y</span><script type="math/tex">x\neq y</script></span> and <span><span class="MathJax_Preview">I(x,y) = 0</span><script type="math/tex">I(x,y) = 0</script></span> if <span><span class="MathJax_Preview">x = y</span><script type="math/tex">x = y</script></span>. </p>
</li>
<li>
<p>Both the loss and training error are good ways of evaluating how well we did in both fitting the model and solving the optimization problem. However, it can only tell us about data we already observed. We don't know what will happen with data we haven't yet seen. To do this, we need to evaluate the <em>testing error</em>. </p>
<p>However, before using the testing data, we must first preprocess it in <em>exactly</em> the same way we preprocessed the training data. That means using the <em>same</em> vector for both the mean and the standard deviation, computed from the <em>trainig data alone</em>.</p>
<p>To preprocess the training data, run  </p>
<div class="highlight"><pre><span></span><code><span class="n">Atest</span> <span class="o">=</span> <span class="n">Atest</span> <span class="o">-</span> <span class="n">ones</span><span class="p">(</span><span class="n">mtest</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">Amean</span><span class="p">;</span>
<span class="n">Atest</span> <span class="o">=</span> <span class="n">Atest</span><span class="o">./</span><span class="p">(</span><span class="n">ones</span><span class="p">(</span><span class="n">mtest</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">.*</span><span class="n">max</span><span class="o">.</span><span class="p">(</span><span class="n">Astd</span><span class="p">,</span><span class="mi">1</span><span class="p">));</span>
</code></pre></div>

<p>without recomputing <em>Amean</em> or <em>Astd</em>. Discuss briefly why not recomputing these constants is so important. </p>
</li>
</ol>
<p>Linear regression models are a great "first pass" algorithm to classify data, because they are so easy to implement, and can be used to double check if the data preprocessing was done correctly. However, there are many reasons why they may not be the best classification tool. In the second half, we will investigate a slightly more sophisticated model, more suited for classification.</p>
</li>
<li>
<p><strong>Logistic regression</strong> Rather than fitting data linearly to labels +1 and -1, in logistic regression, we are fitting a <em>likelihood</em> to 0 or 1. </p>
<p>Specifically, for a data vector <span><span class="MathJax_Preview">a\in \R^n</span><script type="math/tex">a\in \R^n</script></span> and label <span><span class="MathJax_Preview">b\in \{0,1\}</span><script type="math/tex">b\in \{0,1\}</script></span>, we define the probability that label <span><span class="MathJax_Preview">b</span><script type="math/tex">b</script></span> is associated with data vector <span><span class="MathJax_Preview">a</span><script type="math/tex">a</script></span> as</p>
<div>
<div class="MathJax_Preview">\text{Likelihood} = \pr(\text{data}|\text{obs}) = \pr(b|a,x) =
\begin{cases}
\sigma(a_i^Tx) &amp; \text{ if } b = 1,\\
1-\sigma(a_i^Tx) &amp; \text{ if } b = 0
\end{cases} </div>
<script type="math/tex; mode=display">\text{Likelihood} = \pr(\text{data}|\text{obs}) = \pr(b|a,x) =
\begin{cases}
\sigma(a_i^Tx) & \text{ if } b = 1,\\
1-\sigma(a_i^Tx) & \text{ if } b = 0
\end{cases} </script>
</div>
<p>where</p>
<div>
<div class="MathJax_Preview">\sigma(s) = \frac{1}{1+e^{-s}}</div>
<script type="math/tex; mode=display">\sigma(s) = \frac{1}{1+e^{-s}}</script>
</div>
<p>is the <em>sigmoid</em> function (plotted below.)</p>
<p><center>
    <img src="../figures/sigmoid.png" width = "300"> 
</center></p>
<p>This function can be interpreted as a "soft switching" function; the input <span><span class="MathJax_Preview">s</span><script type="math/tex">s</script></span> can be viewed as a "confidence level" of the prediction, and is large and positive if you believe <span><span class="MathJax_Preview">b = 1</span><script type="math/tex">b = 1</script></span>, and large and negative if you believe <span><span class="MathJax_Preview">b = 0</span><script type="math/tex">b = 0</script></span>. When the prediction is not confident, then the output is close to 0. The idea here is that by fitting this model, we don't add numerical artifacts by being "too confident"--e.g. no very large numbers as a result of good data.</p>
<p>Now assume that for our training data <span><span class="MathJax_Preview">\{a_1,...,a_m\}</span><script type="math/tex">\{a_1,...,a_m\}</script></span> and labels <span><span class="MathJax_Preview">\{b_1,...,b_m\}</span><script type="math/tex">\{b_1,...,b_m\}</script></span> are i.i.d. Then the likelihood of observing this entire training set is </p>
<div>
<div class="MathJax_Preview">\text{Likelihood} =  \prod_{i=1}^m\pr(b_i|a_i,x) = \prod_{i=1}^m \sigma(a_i^Tx)^{b_i} (1-\sigma(a_i^Tx))^{1-b_i}</div>
<script type="math/tex; mode=display">\text{Likelihood} =  \prod_{i=1}^m\pr(b_i|a_i,x) = \prod_{i=1}^m \sigma(a_i^Tx)^{b_i} (1-\sigma(a_i^Tx))^{1-b_i}</script>
</div>
<p>where the last step incodes the case switching.</p>
<p>Our goal is to maximize this likelihood. However, this function is not convex, and is rather complicated; computing the gradient or Hessian is not trivial. Therefore, we maximize the <em>log</em> likelihood, solving instead </p>
<div>
<div class="MathJax_Preview">\maximize_{x} \quad f(x) := \log\left(\prod_{i=1}^m \sigma(a_i^Tx)^{b_i} (1-\sigma(a_i^Tx))^{1-b_i}\right) .</div>
<script type="math/tex; mode=display">\maximize_{x} \quad f(x) := \log\left(\prod_{i=1}^m \sigma(a_i^Tx)^{b_i} (1-\sigma(a_i^Tx))^{1-b_i}\right) .</script>
</div>
<p>The loss function is the negative log likelihood.</p>
<ol>
<li>
<p><strong>Conceptual questions.</strong></p>
<ol>
<li>
<p>Explain why it is equivalent to maximize the log likelihood and likelihood.</p>
</li>
<li>
<p>Simplify the loss function, and derive the gradient and Hessian. Is the function convex, concave, or neither?</p>
</li>
</ol>
</li>
<li>
<p><strong>Coding questions</strong></p>
<ol>
<li>
<p>In logistic regression, we are dealing with 0,1 labels rather than -1,1 labels. To fix this, take the <span><span class="MathJax_Preview">b</span><script type="math/tex">b</script></span> vector and readjust: for example, <em>b = (b+1)/2.</em></p>
</li>
<li>
<p>Using an initial value <span><span class="MathJax_Preview">x^{(0)} = 0</span><script type="math/tex">x^{(0)} = 0</script></span>, code up gradient descent to minimize this new loss function. Run for 1000 iterations with fixed step size <span><span class="MathJax_Preview">1/m</span><script type="math/tex">1/m</script></span> ( m =  total number of training samples.) Plot  the model loss as a function of iteration, and report the final train and test misclassification rate.</p>
<p>(<em>If you worry that <span><span class="MathJax_Preview">\log(\sigma(a_i^Tx))=-\infty</span><script type="math/tex">\log(\sigma(a_i^Tx))=-\infty</script></span> or <span><span class="MathJax_Preview">\log(1-\sigma(a_i^Tx))=-\infty</span><script type="math/tex">\log(1-\sigma(a_i^Tx))=-\infty</script></span> because the sigmoid function returns 0 or 1, you may replace <span><span class="MathJax_Preview">\sigma(a_i^Tx)</span><script type="math/tex">\sigma(a_i^Tx)</script></span> with <span><span class="MathJax_Preview">\max(\min(\sigma(a^T_i x),\epsilon),\epsilon)</span><script type="math/tex">\max(\min(\sigma(a^T_i x),\epsilon),\epsilon)</script></span> where <span><span class="MathJax_Preview">\epsilon</span><script type="math/tex">\epsilon</script></span> is some small number.</em>)</p>
</li>
<li>
<p>Using an initial value <span><span class="MathJax_Preview">x^{(0)} = 0</span><script type="math/tex">x^{(0)} = 0</script></span>, code up gradient descent to minimize this new loss function. Run for 1000 iterations with a backtracking line search with <span><span class="MathJax_Preview">s = 1</span><script type="math/tex">s = 1</script></span>, <span><span class="MathJax_Preview">\alpha = \beta = 0.5</span><script type="math/tex">\alpha = \beta = 0.5</script></span>. Plot  the model loss as a function of iteration, and report the final train and test misclassification rate.</p>
</li>
<li>
<p>Compare in 1-2 sentences gradient descent with line search vs constant step size. Which is better?</p>
</li>
<li>
<p>Compare in 1-2 sentences the linear and logistic model. Which is better? Is it better by much? Was the gain worth it?</p>
</li>
</ol>
</li>
</ol>
</li>
<li>
<p><strong>Debugging</strong> Pick three images that fit the leasts squares model the worst, and plot them. Do the same with the logistic model.</p>
</li>
</ol>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2020 Michael Friedlander and Babhru Joshi
          </div>
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.d710d30a.min.js"></script>
      <script src="../../assets/javascripts/bundle.a45f732b.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: [],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.c03f0417.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="../../javascripts/extra.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>