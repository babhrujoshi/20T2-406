


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Home page for CPSC406 Term 2 2020">
      
      
        <link rel="canonical" href="https://babhrujoshi.github.io/20T2-406/homework/hw2/hw2/">
      
      
        <meta name="author" content="Michael P. Friedlander and Babhru Joshi">
      
      <link rel="shortcut icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-5.2.3">
    
    
      
        <title>**CPSC 406: Homework 2 (Due Jan 27, 6pm)** - CPSC406 &mdash; Computational Optimization</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.6e35a1a6.min.css">
      
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
        
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-4736412-7","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}),document.addEventListener("DOMContentSwitch",function(){ga("send","pageview")})</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
  
    <body dir="ltr">
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#cpsc-406-homework-2-due-jan-27-6pm" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="https://babhrujoshi.github.io/20T2-406/" title="CPSC406 &mdash; Computational Optimization" class="md-header-nav__button md-logo" aria-label="CPSC406 &mdash; Computational Optimization">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            CPSC406 &mdash; Computational Optimization
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              **CPSC 406: Homework 2 (Due Jan  27, 6pm)**
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://babhrujoshi.github.io/20T2-406/" title="CPSC406 &mdash; Computational Optimization" class="md-nav__button md-logo" aria-label="CPSC406 &mdash; Computational Optimization">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    CPSC406 &mdash; Computational Optimization
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../../.." title="Home Page" class="md-nav__link">
      Home Page
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../grades/" title="Grades" class="md-nav__link">
      Grades
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../schedule/" title="Schedule" class="md-nav__link">
      Schedule
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      Lecture notes
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Lecture notes" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Lecture notes
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../notes/background/" title="Mathematical background" class="md-nav__link">
      Mathematical background
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../notes/Least_squares/" title="Least squares" class="md-nav__link">
      Least squares
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../notes/QR_factorization/" title="QR factorization" class="md-nav__link">
      QR factorization
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../notes/Regularized_LS/" title="Regularized least squares" class="md-nav__link">
      Regularized least squares
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../notes/Non-linear_LS/" title="Non-linear least squares" class="md-nav__link">
      Non-linear least squares
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../notes/unconstrained/" title="Unconstrained optimization" class="md-nav__link">
      Unconstrained optimization
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../notes/Gradient_Descent/" title="Gradient descent" class="md-nav__link">
      Gradient descent
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../notes/Newtons_method/" title="Newton's method" class="md-nav__link">
      Newton's method
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../notes/Quasi_newton/" title="Quasi-Newton methods" class="md-nav__link">
      Quasi-Newton methods
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../notes/Linear_constraint/" title="Linear constraint" class="md-nav__link">
      Linear constraint
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../notes/Convex_set/" title="Convex sets" class="md-nav__link">
      Convex sets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../notes/Constrained_optimization/" title="Constrained optimization" class="md-nav__link">
      Constrained optimization
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../notes/Convex_function/" title="Convex function" class="md-nav__link">
      Convex function
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../notes/Linear_programming/" title="Linear programming" class="md-nav__link">
      Linear programming
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Homework
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Homework" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Homework
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../" title="Submissions" class="md-nav__link">
      Submissions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../hw1/hw1/" title="Homework 1" class="md-nav__link">
      Homework 1
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  
                
                
                <h1 id="cpsc-406-homework-2-due-jan-27-6pm"><strong>CPSC 406: Homework 2 (Due Jan  27, 6pm)</strong><a class="headerlink" href="#cpsc-406-homework-2-due-jan-27-6pm" title="Permanent link">&para;</a></h1>
<ol>
<li>
<p>(Beck 3.1) Let <span><span class="MathJax_Preview">\mA\in \R^{m\times n}</span><script type="math/tex">\mA\in \R^{m\times n}</script></span>, <span><span class="MathJax_Preview">\vb\in \R^m</span><script type="math/tex">\vb\in \R^m</script></span>, <span><span class="MathJax_Preview">\mL \in \R^{p\times n}</span><script type="math/tex">\mL \in \R^{p\times n}</script></span> and scalar <span><span class="MathJax_Preview">\lambda &gt;0</span><script type="math/tex">\lambda >0</script></span>. Consider the regularized least squares problem</p>
<div>
<div class="MathJax_Preview">\mathop{\text{minimize}}_{\vx\in \R^n} \quad f(\vx) := \|\mA \vx-\vb\|_2^2 + \lambda \|\mL\vx\|_2^2.</div>
<script type="math/tex; mode=display">\mathop{\text{minimize}}_{\vx\in \R^n} \quad f(\vx) := \|\mA \vx-\vb\|_2^2 + \lambda \|\mL\vx\|_2^2.</script>
</div>
<p>Show that this problem has a unique solution if and only if <span><span class="MathJax_Preview">\vnull(\mA) \cap \vnull(\mL) = \{\vzero\}</span><script type="math/tex">\vnull(\mA) \cap \vnull(\mL) = \{\vzero\}</script></span>.
Hint: Look up De Morgan's laws.</p>
</li>
<li>
<p><strong>Multiobjective problems.</strong> Often, in real world applications, we wish to accomplish multiple goals at once. For example, we may wish to buy the 
    biggest house with the least amount of money, or buy the most profitable stocks which also have least risk. These objectives are often competing, and 
    it is impossible to optimize one without negatively impacting the other. </p>
<ol>
<li>
<p><strong>2-norm regularization.</strong> Consider the 2-norm regularized least squares problem</p>
<div>
<div class="MathJax_Preview">\minimize{\vx\in \R^n} \quad \underbrace{\frac{1}{2}\|\mA\vx-\vb\|_2^2}_{f_1(\vx)} + \frac{\gamma}{2}\underbrace{\|\vx\|_2^2}_{f_2(\vx)}</div>
<script type="math/tex; mode=display">\minimize{\vx\in \R^n} \quad \underbrace{\frac{1}{2}\|\mA\vx-\vb\|_2^2}_{f_1(\vx)} + \frac{\gamma}{2}\underbrace{\|\vx\|_2^2}_{f_2(\vx)}</script>
</div>
<p>Show that at optimality, </p>
<div>
<div class="MathJax_Preview">\|\vx\|_2^2 = \sum_{i=1}^n \frac{1}{(d_i+\gamma)^2} g_i^2</div>
<script type="math/tex; mode=display">\|\vx\|_2^2 = \sum_{i=1}^n \frac{1}{(d_i+\gamma)^2} g_i^2</script>
</div>
<p>where <span><span class="MathJax_Preview">\mA\trans\mA = \mQ\mD\mQ\trans</span><script type="math/tex">\mA\trans\mA = \mQ\mD\mQ\trans</script></span> the eigenvalue decomposition and <span><span class="MathJax_Preview">\vg = \mQ\trans\mA\trans\vb</span><script type="math/tex">\vg = \mQ\trans\mA\trans\vb</script></span>. Roughly sketch  what the Pareto-Frontier looks like here, paying 
attention to the limiting behavior (<span><span class="MathJax_Preview">\gamma\to 0</span><script type="math/tex">\gamma\to 0</script></span> and <span><span class="MathJax_Preview">\gamma\to +\infty</span><script type="math/tex">\gamma\to +\infty</script></span>).</p>
</li>
<li>
<p><strong>Sparsity.</strong> As an example, let us consider the problem of sparse recovery, where we wish to find the sparsest solution <span><span class="MathJax_Preview">\vx</span><script type="math/tex">\vx</script></span> such that <span><span class="MathJax_Preview">\mA\vx \approx \vb</span><script type="math/tex">\mA\vx \approx \vb</script></span>. 
    Here, we motivate sparsity by minimizing the 1-norm of <span><span class="MathJax_Preview">\vx</span><script type="math/tex">\vx</script></span>, e.g. </p>
<div>
<div class="MathJax_Preview">f_1(\vx) = \frac{1}{2}\|\mA\vx-\vb\|_2^2, \qquad f_2(\vx) = \|\vx\|_1</div>
<script type="math/tex; mode=display">f_1(\vx) = \frac{1}{2}\|\mA\vx-\vb\|_2^2, \qquad f_2(\vx) = \|\vx\|_1</script>
</div>
<p>and the goal is to make both <span><span class="MathJax_Preview">f_1(\vx)</span><script type="math/tex">f_1(\vx)</script></span> and <span><span class="MathJax_Preview">f_2(\vx)</span><script type="math/tex">f_2(\vx)</script></span> small.</p>
<p>Download data <span><span class="MathJax_Preview">\mA\in \R^{m\times n}</span><script type="math/tex">\mA\in \R^{m\times n}</script></span>(<a href="../hw2_p2_sparse_A.jld"><code>jld</code></a>, <a href="../hw2_p2_sparse_A.csv"><code>csv</code></a>) and <span><span class="MathJax_Preview">\vb\in \R^m</span><script type="math/tex">\vb\in \R^m</script></span>(<a href="../hw2_p2_sparse_b.jld"><code>jld</code></a>, <a href="../hw2_p2_sparse_b.csv"><code>csv</code></a>).
 Using <a href="https://www.juliaopt.org/Convex.jl/stable/">Convex.jl</a> or <a href="http://cvxr.com/cvx/">CVX</a> package solve the following problem for <span><span class="MathJax_Preview">\gamma = 1</span><script type="math/tex">\gamma = 1</script></span>. </p>
<div>
<div class="MathJax_Preview">\minimize{x\in \R^n} \; \underbrace{\frac{1}{2}\|\mA\vx-\vb\|_2^2}_{f_1(\vx)} + \gamma \underbrace{\|\vx\|_1}_{f_2(\vx)}</div>
<script type="math/tex; mode=display">\minimize{x\in \R^n} \; \underbrace{\frac{1}{2}\|\mA\vx-\vb\|_2^2}_{f_1(\vx)} + \gamma \underbrace{\|\vx\|_1}_{f_2(\vx)}</script>
</div>
<p>Report the accuracy (<span><span class="MathJax_Preview">f_1(\vx^*)</span><script type="math/tex">f_1(\vx^*)</script></span> value) and sparsity metric (<span><span class="MathJax_Preview">f_2(\vx^*)</span><script type="math/tex">f_2(\vx^*)</script></span> value).</p>
</li>
<li>
<p>To show the effect of the "sparsity promoter" term (<span><span class="MathJax_Preview">f_2(\vx)</span><script type="math/tex">f_2(\vx)</script></span>), repeat the above exercise for <span><span class="MathJax_Preview">\gamma = 0.01</span><script type="math/tex">\gamma = 0.01</script></span> and <span><span class="MathJax_Preview">\gamma = 10</span><script type="math/tex">\gamma = 10</script></span>. Plot both solutions
     on top of the original signal <span><span class="MathJax_Preview">\vx_0</span><script type="math/tex">\vx_0</script></span>(<a href="../hw2_p2_sparse_signal.jld"><code>jld</code></a>, <a href="../hw2_p2_sparse_signal.csv"><code>csv</code></a>). Which solution gives better signal recovery?</p>
</li>
<li>
<p>Repeat the above exercise for 100 different values of <span><span class="MathJax_Preview">\gamma</span><script type="math/tex">\gamma</script></span>, generated from  <code>exp10.(range(-3, stop=3, length=100))</code>. Plot the cost <span><span class="MathJax_Preview">f_1(\vx)</span><script type="math/tex">f_1(\vx)</script></span> on the 
<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>-axis and <span><span class="MathJax_Preview">f_2(\vx)</span><script type="math/tex">f_2(\vx)</script></span> on the <span><span class="MathJax_Preview">y</span><script type="math/tex">y</script></span>-axis. This is the <em>Pareto frontier</em>. For any cost value pair to the  upper right of this curve, at least one cost can be 
made smaller at no expense to the other. For any cost value pair to the lower left of the curve, the cost values are unattainable. The Pareto frontier 
represents the "best case scenario" set of points. </p>
</li>
<li>
<p>We now consider another example where we motivate smoothness as well as accuracy. Download data <span><span class="MathJax_Preview">\mA\in \R^{m\times n}</span><script type="math/tex">\mA\in \R^{m\times n}</script></span>(<a href="../hw2_p2_smooth_A.jld"><code>jld</code></a>,<a href="../hw2_p2_smooth_A.csv"><code>csv</code></a>) 
    and <span><span class="MathJax_Preview">\vb\in \R^m</span><script type="math/tex">\vb\in \R^m</script></span>(<a href="../hw2_p2_smooth_b.jld"><code>jld</code></a>, <a href="../hw2_p2_smooth_b.csv"><code>csv</code></a>). Again, using <a href="https://www.juliaopt.org/Convex.jl/stable/">Convex.jl</a> or <a href="http://cvxr.com/cvx/">CVX</a> package, 
    solve the following problem for <span><span class="MathJax_Preview">\gamma = 1</span><script type="math/tex">\gamma = 1</script></span>. </p>
<div>
<div class="MathJax_Preview">\minimize{\vx\in \R^n} \; \underbrace{\frac{1}{2}\|\mA\vx-\vb\|_2^2}_{f_1(\vx)} + \gamma \underbrace{\|\mD\vx\|_1}_{f_2(\vx)}</div>
<script type="math/tex; mode=display">\minimize{\vx\in \R^n} \; \underbrace{\frac{1}{2}\|\mA\vx-\vb\|_2^2}_{f_1(\vx)} + \gamma \underbrace{\|\mD\vx\|_1}_{f_2(\vx)}</script>
</div>
<p>where</p>
<div>
<div class="MathJax_Preview">\mD = \bmat 1 &amp; -1 &amp; 0 &amp;\cdots &amp;0&amp;0 \\ 
0 &amp;1 &amp; -1  &amp;\cdots &amp;0&amp;0 \\ 
\vdots &amp; \vdots &amp; \ddots &amp; \ddots &amp; \vdots &amp; \vdots \\
0 &amp; 0 &amp; 0 &amp; \cdots &amp; 1 &amp; -1   \emat \in \R^{n-1\times n}</div>
<script type="math/tex; mode=display">\mD = \bmat 1 & -1 & 0 &\cdots &0&0 \\ 
0 &1 & -1  &\cdots &0&0 \\ 
\vdots & \vdots & \ddots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & \cdots & 1 & -1   \emat \in \R^{n-1\times n}</script>
</div>
<p>Minimize this objective for <span><span class="MathJax_Preview">\gamma = 0.01</span><script type="math/tex">\gamma = 0.01</script></span> and <span><span class="MathJax_Preview">\gamma = 10</span><script type="math/tex">\gamma = 10</script></span>. Plot both solutions on top of the original signal <span><span class="MathJax_Preview">\vx_0</span><script type="math/tex">\vx_0</script></span>(<a href="../hw2_p2_smooth_signal.jld"><code>jld</code></a>,
 <a href="../hw2_p2_smooth_signal.csv"><code>csv</code></a>). Which solutio)n gives better signal recovery?</p>
</li>
<li>
<p>Repeat the above exercise for 100 different values of <span><span class="MathJax_Preview">\gamma</span><script type="math/tex">\gamma</script></span>, generated from <code>exp10.(range(-3, stop=3, length=100))</code>. Plot the Pareto frontier.</p>
</li>
</ol>
</li>
<li>
<p><strong>Non-linear least squares (adapted from Beck 4.6)</strong> The <em>source localization problem</em> consists of minimizing </p>
<div>
<div class="MathJax_Preview">\minimize{\vx\in \R^n} \left\{f(\vx) :=  \sum_{i=1}^m \left(\|\vx-\vc_i\|_2^2 - d_i^2\right)^2\right\}</div>
<script type="math/tex; mode=display">\minimize{\vx\in \R^n} \left\{f(\vx) :=  \sum_{i=1}^m \left(\|\vx-\vc_i\|_2^2 - d_i^2\right)^2\right\}</script>
</div>
<p>for vectors <span><span class="MathJax_Preview">\vc_1,...,\vc_m\in \R^n</span><script type="math/tex">\vc_1,...,\vc_m\in \R^n</script></span> and scalars <span><span class="MathJax_Preview">d_1,...,d_m</span><script type="math/tex">d_1,...,d_m</script></span>. This is of course a nonlinear least squares problem, and thus the Gauss-Newton method can be 
employed to solve it. We will assume that <span><span class="MathJax_Preview">n = 2</span><script type="math/tex">n = 2</script></span>. </p>
<ol>
<li>
<p>Compute the gradient of <span><span class="MathJax_Preview">f(\vx)</span><script type="math/tex">f(\vx)</script></span> at a given point <span><span class="MathJax_Preview">\vx</span><script type="math/tex">\vx</script></span>.</p>
</li>
<li>
<p>Rewrite the problem as </p>
<div>
<div class="MathJax_Preview">\minimize{\vx\in \R^n} \quad \|r(\vx)\|_2^2</div>
<script type="math/tex; mode=display">\minimize{\vx\in \R^n} \quad \|r(\vx)\|_2^2</script>
</div>
<p>that is, identify <span><span class="MathJax_Preview">r(\vx) : \R^n \to  \R^m</span><script type="math/tex">r(\vx) : \R^n \to  \R^m</script></span>. Compute also the Jacobian of <span><span class="MathJax_Preview">r(\vx)</span><script type="math/tex">r(\vx)</script></span></p>
<div>
<div class="MathJax_Preview">J(\vx) = \bmat \nabla r_1(\vx)\trans  \\ \vdots \\ \nabla r_m(\vx)\trans\emat.</div>
<script type="math/tex; mode=display">J(\vx) = \bmat \nabla r_1(\vx)\trans  \\ \vdots \\ \nabla r_m(\vx)\trans\emat.</script>
</div>
</li>
<li>
<p>Show that as long as all the points <span><span class="MathJax_Preview">\vc_1,...,\vc_m</span><script type="math/tex">\vc_1,...,\vc_m</script></span> do not reside on the same line in the plane, and at each iterate <span><span class="MathJax_Preview">\vx^{(k)} \neq \vc_i</span><script type="math/tex">\vx^{(k)} \neq \vc_i</script></span> for 
    any <span><span class="MathJax_Preview">i = 1,...,m</span><script type="math/tex">i = 1,...,m</script></span>, the method is well-defined, meaning that the linear least squares problem solved at each iteration has a unique solution.</p>
</li>
<li>
<p>We will now implement some numerical methods on this problem. Download data <span><span class="MathJax_Preview">\mC\in \R^{2\times 5}</span><script type="math/tex">\mC\in \R^{2\times 5}</script></span>(<a href="../hw2_p3_C.jld"><code>jld</code></a>, <a href="../hw2_p3_C.csv"><code>csv</code></a>),
    <span><span class="MathJax_Preview">\vd\in \R^5</span><script type="math/tex">\vd\in \R^5</script></span>(<a href="../hw2_p3_d.jld"><code>jld</code></a>, <a href="../hw2_p3_d.csv"><code>csv</code></a>), and <span><span class="MathJax_Preview">\vx \in \R^2</span><script type="math/tex">\vx \in \R^2</script></span>(<a href="../hw2_p3_signal.jld"><code>jld</code></a>, <a href="../hw2_p3_signal.csv"><code>csv</code></a>). The columns of the <span><span class="MathJax_Preview">2 \times 5</span><script type="math/tex">2 \times 5</script></span> matrix <span><span class="MathJax_Preview">\mC</span><script type="math/tex">\mC</script></span> are the locations of the five sensors,
    <span><span class="MathJax_Preview">\vx</span><script type="math/tex">\vx</script></span> is the "true" location of the source, and <span><span class="MathJax_Preview">\vd</span><script type="math/tex">\vd</script></span> is the vector of noisy measurements between the source and the sensors.
    In all cases, initialize with <span><span class="MathJax_Preview">\vx^{(0)} = (1000, -500)\trans</span><script type="math/tex">\vx^{(0)} = (1000, -500)\trans</script></span>.</p>
<ol>
<li>
<p>The <em>gradient descent</em> method operates via the iteration scheme</p>
<div>
<div class="MathJax_Preview">\vx^{(k+1)} = \vx^{(k)} - \alpha^{(k)} \nabla f(\vx^{(k)})</div>
<script type="math/tex; mode=display">\vx^{(k+1)} = \vx^{(k)} - \alpha^{(k)} \nabla f(\vx^{(k)})</script>
</div>
<p>for a choice of step size <span><span class="MathJax_Preview">\alpha^{(k)}</span><script type="math/tex">\alpha^{(k)}</script></span>. Implement the gradient descent method for a constant step size <span><span class="MathJax_Preview">\alpha^{(k)} = \bar \alpha</span><script type="math/tex">\alpha^{(k)} = \bar \alpha</script></span>. 
Try several values until you find the largest value of <span><span class="MathJax_Preview">\bar \alpha</span><script type="math/tex">\bar \alpha</script></span> such that the method does not diverge. Hint: try several orders of 
magnitude from <span><span class="MathJax_Preview">10^{-10}</span><script type="math/tex">10^{-10}</script></span> to <span><span class="MathJax_Preview">1</span><script type="math/tex">1</script></span>.</p>
</li>
<li>
<p>Implement gradient descent with backtracking line search. Use parameters <span><span class="MathJax_Preview">s=1, \alpha=\beta=0.5</span><script type="math/tex">s=1, \alpha=\beta=0.5</script></span>. (Refer also to page 51 in 
    <a href="https://epubs.siam.org/doi/book/10.1137/1.9781611973655">Beck</a>.)</p>
</li>
<li>
<p>Implement damped Gauss-Newton to minimize <span><span class="MathJax_Preview">f(\vx)</span><script type="math/tex">f(\vx)</script></span>. Use the largest constant step size <span><span class="MathJax_Preview">\bar \alpha \leq 1</span><script type="math/tex">\bar \alpha \leq 1</script></span> such that the method does 
    not diverge.</p>
</li>
<li>
<p>Implement damped-Gauss-Newton with  backtracking line search. Use parameters <span><span class="MathJax_Preview">s=1, \alpha=\beta=0.5</span><script type="math/tex">s=1, \alpha=\beta=0.5</script></span>. (You may need to force the line 
    search to stop after a constant number of iterations.)</p>
</li>
</ol>
</li>
</ol>
<p>Submit a plot that shows <span><span class="MathJax_Preview">f(\vx^{(k)})</span><script type="math/tex">f(\vx^{(k)})</script></span>  tracked for <span><span class="MathJax_Preview">k = 1,..., 100</span><script type="math/tex">k = 1,..., 100</script></span> iterations, for all four solvers. Report also the values for <span><span class="MathJax_Preview">\bar \alpha</span><script type="math/tex">\bar \alpha</script></span> in 
the constant step size cases. Write 2-3 sentences comparing each approach. Also, describe any deviations of your code to the standard approach. 
(e.g. any tweaks.)</p>
</li>
</ol>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2020 Michael Friedlander and Babhru Joshi
          </div>
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../assets/javascripts/vendor.d710d30a.min.js"></script>
      <script src="../../../assets/javascripts/bundle.a45f732b.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "../../..",
          features: [],
          search: Object.assign({
            worker: "../../../assets/javascripts/worker/search.c03f0417.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="../../../javascripts/extra.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>